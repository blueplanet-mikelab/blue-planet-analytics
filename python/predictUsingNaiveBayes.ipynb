{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "D:\\AOM_Document\\blue-planet-pantip-analytics\\python\n"
    }
   ],
   "source": [
    "import urllib.request, json, os, pymongo, sys\n",
    "from math import sqrt, exp, pi\n",
    "path_to_current = \"D:/AOM_Document/blue-planet-pantip-analytics/python/\"\n",
    "sys.path.append(path_to_current)\n",
    "os.chdir(path_to_current)\n",
    "print(os.getcwd())\n",
    "from utils.TFIDFCalculationUtil import calculateFullTFIDF, createWordsSummary\n",
    "from utils.fileWritingUtil import removeAndWriteFile\n",
    "from utils.manageContentUtil import cleanContent, getStopWords\n",
    "\n",
    "with open('./config/url.json') as json_data_file:\n",
    "    URLCONFIG = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(model, toPredWord, allWordList):\n",
    "    total_rows = sum([len(model[label][\"topic_ids\"]) for label in model])\n",
    "    probabilities = {}\n",
    "    count = {}\n",
    "    for class_label, class_dict in model.items():\n",
    "        # init\n",
    "        count[class_label] = 0\n",
    "        probabilities[class_label] = len(class_dict[\"topic_ids\"])/float(total_rows)\n",
    "        # print(class_label,\"----init->\",len(class_dict[\"topic_ids\"]),\"/\",float(total_rows),\"=\",probabilities[class_label])\n",
    "        if len(class_dict[\"topic_ids\"]) == 1: #exclude\n",
    "            probabilities[class_label] = -1\n",
    "            break\n",
    "        \n",
    "        for word in allWordList:\n",
    "            x = [w[\"count\"] for w in toPredWord if w[\"key\"]==word]\n",
    "            toPredWordCount = x[0] if len(x) > 0 else 0\n",
    "            y = [valDict for key, valDict in class_dict[\"words_count\"].items() if key==word]\n",
    "            if len(y) == 0:\n",
    "                continue #not care other words outside class \n",
    "            mean = y[0][\"mean\"]\n",
    "            stdev = y[0][\"stdev\"]\n",
    "            # print(\"---word:{},x:{},m:{},std:{}\".format(word,toPredWordCount,mean,stdev))\n",
    "            probabilities[class_label] *= calculate_probability(toPredWordCount, mean, stdev)\n",
    "            if probabilities[class_label] < (10**(-100)):\n",
    "                probabilities[class_label] = probabilities[class_label] * (10**100)\n",
    "                count[class_label] +=1\n",
    "            elif probabilities[class_label] > (10**(100)):\n",
    "                probabilities[class_label] = probabilities[class_label] * (10**(-100))\n",
    "                count[class_label] -=1 \n",
    "            # if first:\n",
    "            #     print(\">>\",probabilities[class_label])\n",
    "            \n",
    "        # print(\"----count:\",count[class_label])\n",
    "    return probabilities, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class for a given row\n",
    "def predict(model, toPredWord, allWordList):\n",
    "    probabilities, countDict = calculate_class_probabilities(model, toPredWord, allWordList)\n",
    "    if len(probabilities) != len(model):\n",
    "        return \"cannot predict model because of less data\"\n",
    "    print(\"prop:\",probabilities)\n",
    "    print(\"count:\", countDict)\n",
    "    bestCount = -999999\n",
    "    for cclass, count in countDict.items():\n",
    "        if count > bestCount:\n",
    "            bestCount = count\n",
    "            bestClass = cclass\n",
    "        # print(cclass, count, \"but best ->\", bestClass, bestCount)\n",
    "    if len([c for c in countDict.values() if c==bestCount]) > 1:\n",
    "        bestKeys = [k for k, v in probabilities.items() if v == bestCount]\n",
    "        bestProp, bestClass = -1, None\n",
    "        for key in bestKeys:\n",
    "            currentProp = probabilities[key]\n",
    "            if bestClass == None:\n",
    "                bestClass = key\n",
    "                bestProp = currentProp\n",
    "            elif currentProp > bestProp:\n",
    "                bestProp = currentProp\n",
    "                bestClass = key\n",
    "    return bestClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "---------calculateFullTFIDF--------\n0----39396463\n-----------Mountain-----------\nprop:{'yes': 9.0935623821773, 'no': 1.5456618177266232e+38}\ncount:{'yes': -14, 'no': -21}\nMountain isyes\n-----------Entertainment-----------\nprop:{'yes': 1.7313729242057985e+73, 'no': 8.137678391494825e+53}\ncount:{'yes': 0, 'no': -33}\nEntertainment isyes\n-----------Photography-----------\nprop:{'yes': 8.3060965729415e+32, 'no': 475780495.3828881}\ncount:{'yes': -29, 'no': -6}\nPhotography isno\n-----------Eating-----------\nprop:{'yes': 7.666365875637956e+92, 'no': 4.267605916662807e+66}\ncount:{'yes': -18, 'no': -16}\nEating isno\n-----------WaterActivities-----------\nprop:{'yes': 746106494342.8712, 'no': 4.430646649461576}\ncount:{'yes': -3, 'no': -32}\nWaterActivities isyes\n-----------Religion-----------\nprop:{'yes': 2.0563329782455058e+61, 'no': 1.3834135413577165e+72}\ncount:{'yes': -9, 'no': -24}\nReligion isyes\n-----------Honeymoon-----------\nprop:{'yes': 2.3370164208487413e-56, 'no': 5.004729673569536e+58}\ncount:{'yes': 3, 'no': -37}\nHoneymoon isyes\n-----------Backpack-----------\nprop:{'yes': 4.944583873152302e+83, 'no': 38314261.07330717}\ncount:{'yes': -2, 'no': -32}\nBackpack isyes\n-----------Event-----------\nEvent iscannot predict model because of less data\n-----------------------------------------------\nThemes:['Mountain', 'Entertainment', 'WaterActivities', 'Religion', 'Honeymoon', 'Backpack']\n"
    }
   ],
   "source": [
    "#! 1. read models and listword\n",
    "with open('./5-themeModels-finish.json','r', encoding=\"utf8\") as theme_json:\n",
    "    themeModels = json.load(theme_json)\n",
    "with open('5-allwordList.json','r', encoding=\"utf8\") as allword_json:\n",
    "    allWordList = json.load(allword_json)\n",
    "\n",
    "#! 2-1. get data\n",
    "topicID = 39396463\n",
    "with urllib.request.urlopen(URLCONFIG[\"mike_thread\"] + str(topicID)) as url:\n",
    "    threadData = json.loads(url.read().decode())\n",
    "\n",
    "#! 2-2. retrieve title+destription+comment\n",
    "title = threadData['_source']['title']\n",
    "desc = threadData['_source']['desc']\n",
    "userID = threadData['_source']['uid']\n",
    "comments = [comment['desc'] for comment in threadData['_source']['comments'] if comment['uid']==userID]\n",
    "rawContent = title + desc + ' '.join(comments)\n",
    "\n",
    "#! 2-3. tokenize+wordsummary\n",
    "wordsSum, tokensLength, wordSumDict = createWordsSummary(cleanContent(rawContent), getStopWords(addMore=True))\n",
    "# freqDictList.append({\"topic_id\": topicID, \"words_sum\": wordsSum, \"tokens_length\": tokensLength, \"created_at\":datetime.datetime.now()})\n",
    "freqDict = {\"topic_id\": topicID, \"words_sum\": wordsSum, \"tokens_length\": tokensLength}\n",
    "\n",
    "threadScores = calculateFullTFIDF([freqDict])\n",
    "threadScore = threadScores[0]\n",
    "\n",
    "#! 4. cut off some keys using tfidf by scores\n",
    "tscoresList = threadScore['scores']\n",
    "if len(tscoresList) > 100:\n",
    "    headcut = 0\n",
    "    tailcut = len(tscoresList) - int(0.46*len(tscoresList))\n",
    "    prevVal = -1\n",
    "    for idx, scores in enumerate(tscoresList):\n",
    "        if prevVal == -1:\n",
    "            prevVal = scores['tfidf']\n",
    "\n",
    "        if (idx < headcut or idx > tailcut) and scores['tfidf'] != prevVal:\n",
    "            tscoresList.remove(scores)\n",
    "        else:\n",
    "            prevVal = scores['tfidf']\n",
    "\n",
    "threadScore['significant_words'] = tscoresList\n",
    "# tscoresList = [{\n",
    "#     \"key\": \"ที่อื่น\",\n",
    "#     \"count\": 1,\n",
    "#     \"tf\": 0.0014144271570014145,\n",
    "#     \"idf\": 1.8082887711792655,\n",
    "#     \"tfidf\": 0.00255769274565667\n",
    "# },...]\n",
    "\n",
    "#! 4-1. Predict\n",
    "threadThemes = []\n",
    "for theme, model in themeModels.items(): #model = {\"yes\":..., \"no\":...}\n",
    "    print(\"-----------\",theme, \"-----------\")\n",
    "    isTheme = predict(model, tscoresList, allWordList)\n",
    "    print(theme,\" is \",isTheme)\n",
    "    # break\n",
    "    if isTheme == \"yes\":\n",
    "        threadThemes.append(theme)\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"Themes:\",threadThemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}