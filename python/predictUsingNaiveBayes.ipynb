{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "D:\\AOM_Document\\blue-planet-pantip-analytics\\python\n"
    }
   ],
   "source": [
    "import urllib.request, json, os, pymongo, sys\n",
    "from math import sqrt, exp, pi\n",
    "path_to_current = \"D:/AOM_Document/blue-planet-pantip-analytics/python/\"\n",
    "sys.path.append(path_to_current)\n",
    "os.chdir(path_to_current)\n",
    "print(os.getcwd())\n",
    "from utils.TFIDFCalculationUtil import calculateFullTFIDF, createWordsSummary\n",
    "from utils.fileWritingUtil import removeAndWriteFile\n",
    "from utils.manageContentUtil import cleanContent, getStopWords\n",
    "\n",
    "with open('./config/url.json') as json_data_file:\n",
    "    URLCONFIG = json.load(json_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "\texponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "\treturn (1 / (sqrt(2 * pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(model, toPredWord, allWordList):\n",
    "    total_rows = sum([len(model[label][\"topic_ids\"]) for label in model])\n",
    "    probabilities = {}\n",
    "    count = {}\n",
    "    for class_label, class_dict in model.items():\n",
    "        # init\n",
    "        count[class_label] = 0\n",
    "        probabilities[class_label] = len(class_dict[\"topic_ids\"])/float(total_rows)\n",
    "        print(class_label,\"----init->\",len(class_dict[\"topic_ids\"]),\"/\",float(total_rows),\"=\",probabilities[class_label])\n",
    "        if len(class_dict[\"topic_ids\"]) == 1: #exclude\n",
    "            probabilities[class_label] = -1\n",
    "            break\n",
    "        \n",
    "        for word in allWordList:\n",
    "            x = [w[\"count\"] for w in toPredWord if w[\"key\"]==word]\n",
    "            toPredWordCount = x[0] if len(x) > 0 else 0\n",
    "            y = [valDict for key, valDict in class_dict[\"words_count\"].items() if key==word]\n",
    "            if len(y) == 0:\n",
    "                continue #not care other words outside class \n",
    "            mean = y[0][\"mean\"]\n",
    "            stdev = y[0][\"stdev\"]\n",
    "            # print(\"---word:{},x:{},m:{},std:{}\".format(word,toPredWordCount,mean,stdev))\n",
    "            probabilities[class_label] *= calculate_probability(toPredWordCount, mean, stdev)\n",
    "            if probabilities[class_label] < (10**(-100)):\n",
    "                probabilities[class_label] = probabilities[class_label] * (10**100)\n",
    "                count[class_label] +=1\n",
    "            elif probabilities[class_label] > (10**(100)):\n",
    "                probabilities[class_label] = probabilities[class_label] * (10**(-100))\n",
    "                count[class_label] -=1 \n",
    "            # if first:\n",
    "            #     print(\">>\",probabilities[class_label])\n",
    "            \n",
    "        print(\"----count:\",count[class_label])\n",
    "    return probabilities, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class for a given row\n",
    "def predict(model, toPredWord, allWordList):\n",
    "    probabilities, countDict = calculate_class_probabilities(model, toPredWord, allWordList)\n",
    "    if len(probabilities) != len(model):\n",
    "        return \"cannot predict model because of less data\"\n",
    "    print(\"prop:\",probabilities)\n",
    "    print(\"count:\", countDict)\n",
    "    bestCount = -999999\n",
    "    for cclass, count in countDict.items():\n",
    "        if count > bestCount:\n",
    "            bestCount = count\n",
    "            bestClass = cclass\n",
    "        # print(cclass, count, \"but best ->\", bestClass, bestCount)\n",
    "    if len([c for c in countDict.values() if c==bestCount]) > 1:\n",
    "        bestKeys = [k for k, v in probabilities.items() if v == bestCount]\n",
    "        bestProp, bestClass = -1, None\n",
    "        for key in bestKeys:\n",
    "            currentProp = probabilities[key]\n",
    "            if bestClass == None:\n",
    "                bestClass = key\n",
    "                bestProp = currentProp\n",
    "            elif currentProp > bestProp:\n",
    "                bestProp = currentProp\n",
    "                bestClass = key\n",
    "    return bestClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './5-themeModels-finish.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-991812419385>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#! 1. read models and listword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./5-themeModels-finish.json'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtheme_json\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mthemeModels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheme_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'5-allwordList.json'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mallword_json\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mallWordList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallword_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './5-themeModels-finish.json'"
     ]
    }
   ],
   "source": [
    "#! 1. read models and listword\n",
    "with open('./5-themeModels-finish.json','r', encoding=\"utf8\") as theme_json:\n",
    "    themeModels = json.load(theme_json)\n",
    "with open('5-allwordList.json','r', encoding=\"utf8\") as allword_json:\n",
    "    allWordList = json.load(allword_json)\n",
    "\n",
    "#! 2-1. get data\n",
    "topicID = 39396463\n",
    "with urllib.request.urlopen(URLCONFIG[\"mike_thread\"] + str(topicID)) as url:\n",
    "    threadData = json.loads(url.read().decode())\n",
    "\n",
    "#! 2-2. retrieve title+destription+comment\n",
    "title = threadData['_source']['title']\n",
    "desc = threadData['_source']['desc']\n",
    "userID = threadData['_source']['uid']\n",
    "comments = [comment['desc'] for comment in threadData['_source']['comments'] if comment['uid']==userID]\n",
    "rawContent = title + desc + ' '.join(comments)\n",
    "\n",
    "#! 2-3. tokenize+wordsummary\n",
    "wordsSum, tokensLength, wordSumDict = createWordsSummary(cleanContent(rawContent), getStopWords(addMore=True))\n",
    "# freqDictList.append({\"topic_id\": topicID, \"words_sum\": wordsSum, \"tokens_length\": tokensLength, \"created_at\":datetime.datetime.now()})\n",
    "freqDict = {\"topic_id\": topicID, \"words_sum\": wordsSum, \"tokens_length\": tokensLength}\n",
    "\n",
    "threadScores = calculateFullTFIDF([freqDict])\n",
    "threadScore = threadScores[0]\n",
    "\n",
    "#! 4. cut off some keys using tfidf by scores\n",
    "tscoresList = threadScore['scores']\n",
    "if len(tscoresList) > 100:\n",
    "    headcut = 0\n",
    "    tailcut = len(tscoresList) - int(0.46*len(tscoresList))\n",
    "    prevVal = -1\n",
    "    for idx, scores in enumerate(tscoresList):\n",
    "        if prevVal == -1:\n",
    "            prevVal = scores['tfidf']\n",
    "\n",
    "        if (idx < headcut or idx > tailcut) and scores['tfidf'] != prevVal:\n",
    "            tscoresList.remove(scores)\n",
    "        else:\n",
    "            prevVal = scores['tfidf']\n",
    "\n",
    "threadScore['significant_words'] = tscoresList\n",
    "# tscoresList = [{\n",
    "#     \"key\": \"ที่อื่น\",\n",
    "#     \"count\": 1,\n",
    "#     \"tf\": 0.0014144271570014145,\n",
    "#     \"idf\": 1.8082887711792655,\n",
    "#     \"tfidf\": 0.00255769274565667\n",
    "# },...]\n",
    "\n",
    "#! 4-1. Predict\n",
    "threadThemes = []\n",
    "for theme, model in themeModels.items(): #model = {\"yes\":..., \"no\":...}\n",
    "    print(\"-----------\",theme, \"-----------\")\n",
    "    isTheme = predict(model, tscoresList, allWordList)\n",
    "    print(theme,\"is\",isTheme)\n",
    "    # break\n",
    "    if isTheme == \"yes\":\n",
    "        threadThemes.append(theme)\n",
    "\n",
    "print(\"-----------------------------------------------\")\n",
    "print(\"Themes:\",threadThemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}